# Redis
## Redis 对象

   	redis使用对象来表示数据库中的键和值，每次当我们在redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键(键对象)，另一个对象用作键值对的值(值对象)。 

   	redis的每种对象都由**对象结构**(redisObject)与对应编码的**数据结构**组合而成，**redis支持5种对象类型，分别是字符串(string)、列表(list)、哈希(hash)、集合(set)、有序集合(zset)**

​	redis中的键和值都是由对象组成的，而对象是由**对象结构**和**数据结构**共同组成的。redis中的键，都是用字符串来存储的，即对于redis数据库中的键值对来说，**键总是一个字符串对象**，而**值可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象中的其中一种。**

[参考](https://developer.aliyun.com/article/710228)


## 说一下Redis主从复制？完整重同步，部分重同步 

### （一）主从复制概述
主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。

默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。

### （二）主从复制的实现原理

主从复制过程大体可以分为3个阶段：**连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段**；

#### 1. 连接建立阶段

##### 步骤1：保存主节点信息

从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。

需要注意的是，**slaveof**是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。

##### 步骤2：建立socket连接

从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功，则：

从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。

主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，**并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。**

##### 步骤3：发送ping命令

从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。
##### 步骤4：身份验证
如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；
##### 步骤5：发送从节点端口信息
身份验证之后，从节点会向主节点发送其监听的端口号

#### 2. 数据同步阶段

* 主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。

* 数据同步阶段是主从复制最核心的阶段，根**据主从节点当前状态的不同，可以分为全量复制和部分复制**，下面会有一章专门讲解这两种复制方式以及psync命令的执行过程，这里不再详述。

* 需**要注意的是，在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。**原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。

#### 3. 命令传播阶段
  数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。

### （四）【数据同步阶段】全量复制和部分复制以及psync命令

* 在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；

* 在Redis2.8及以后，从节点可以发送**psync**命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。
	* 1. 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。
	* 2. 部分复制：用于网络中断等情况后的复制，**只将中断期间主节点执行的写命令发送给从节点，**与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。

#### 1. 全量复制

Redis通过psync命令进行全量复制的过程如下：

（1）从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行部分复制；具体判断过程需要在讲述了部分复制原理后再介绍。

（2）主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令

（3）主节点的bgsave执行完成后，将RDB文件发送给从节点；**从节点首先清除自己的旧数据，然后载入接收的RDB文件**，将数据库状态更新至主节点执行bgsave时的数据库状态

（4）主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态

（5）如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态

#### 2. 部分复制

由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。

部分复制的实现，依赖于三个重要的概念：

#### （1）复制偏移量

主节点和从节点分别维护一个复制偏移量（offset），代表的是**主节点向从节点传递的字节数**；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。

offset用于判断主从节点的数据库状态是否一致：

* 如果二者offset相同，则一致；
* 如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而**offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。**

#### （2）复制积压缓冲区

**复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。**

在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。

由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。

**从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：**

- **如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；**
- **如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。**

#### （3）服务器运行ID(runid)

每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid：

![img](https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011537662-712436367.png)

**主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：**

- 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；

- 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。

 #### 3. psync命令的执行

   在了解了复制偏移量、复制积压缓冲区、节点运行id之后，本节将介绍psync命令的参数和返回值，从而说明psync命令执行过程中，**主从节点是如何确定使用全量复制还是部分复制的。**

   psync命令的执行过程可以参见下图（图片来源：《Redis设计与实现》）：

   ![img](https://images2018.cnblogs.com/blog/1174710/201806/1174710-20180628011547892-692403928.png) 

   （1）首先，从节点根据当前状态，决定如何调用psync命令：

   - 如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制；
   - 如果从节点之前执行了slaveof，则发送命令为psync <runid> <offset>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。

   （2）主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制：

   - 如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；
   - 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；
   - 如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC <runid> <offset>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。

   [参考](https://www.cnblogs.com/kismetv/p/9236731.html)

## 5. Redis主从数据不一致情况？

###  **(一) 常见的数据库集群架构如何？**

**答**：一主多从，主从同步，读写分离。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9ZcmV6eGNraFlPejAxY09TRDE0NnhuN1pFU0RIeFlsODZ1YzVsNkswTDYwVDVoY3ZWaWFnMk4zUWE0U3FOSjJxb0l0T3ZReTdpYk01Q0xpYUZUZmZtZ2d1QS82NDA_d3hfZm10PXBuZyZ0cD13ZWJwJnd4ZnJvbT01Jnd4X2xhenk9MSZ3eF9jbz0x)

如上图：

（1）一个**主库提供写服务**

（2）多个**从库提供读服务**，可以增加从库提升读性能

（3）主从之间同步数据

*画外音：任何方案不要忘了本心，加**从库的本心，是提升读性能**。*

### **（二）为什么会出现不一致？**

**答**：主从同步有时延，这个时延期间读从库，可能读到不一致的数据。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9ZcmV6eGNraFlPejAxY09TRDE0NnhuN1pFU0RIeFlsOFE1QzVaekJUcTZvM0E2emlhRlFhSnlPVmpZcHVvaWMybUNCUkI2REFRNzVJUnQ1SmljdEd4NWdLQS82NDA_d3hfZm10PXBuZyZ0cD13ZWJwJnd4ZnJvbT01Jnd4X2xhenk9MSZ3eF9jbz0x)

如上图：

（1）服务发起了一个写请求

（2）服务又发起了一个读请求，此时同步未完成，读到一个不一致的脏数据

（3）数据库主从同步最后才完成

*画外音：任何数据冗余，必将引发一致性问题。*

### **（三）如何避免这种主从延时导致的不一致？** 

**方案一：忽略**

任何脱离业务的架构设计都是耍流氓，绝大部分业务，例如：百度搜索，淘宝订单，QQ消息，58帖子都允许短时间不一致。

*画外音：如果业务能接受，最推崇此法。*

 

如果业务能够接受，别把系统架构搞得太复杂。

 

**方案二：强制读主**

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9ZcmV6eGNraFlPejAxY09TRDE0NnhuN1pFU0RIeFlsOEQ1b1Eyb2hNeEFpYTRpY1VyZ3dHYWhRbmpxdFE1ODFGQUtHNFRIZGFSZmliaWNpYkc2d0E2RGtQdGV3LzY0MD93eF9mbXQ9cG5nJnRwPXdlYnAmd3hmcm9tPTUmd3hfbGF6eT0xJnd4X2NvPTE)

如上图：

（1）使用一个高可用主库提供数据库服务

（2）读和写都落到主库上

（3）采用**缓存来提升系统读性能**

这是很常见的微服务架构，可以避免数据库主从一致性问题。

**方案三：选择性读主**

强制读主过于粗暴，毕竟只有少量写请求，很短时间，可能读取到脏数据。

 

有没有可能实现，只有这一段时间，**可能读到从库脏数据的读请求读主，平时读从**呢？

 

可以利用一个**缓存记录必须读主的数据（少量写请求发生的时候）**。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9ZcmV6eGNraFlPejAxY09TRDE0NnhuN1pFU0RIeFlsOGlhUVpyTlh2VlBLT2pXMU1qdnRZVkc3UUVvaFpjTVBqVUdhc1g3bTFpYkFFZHVOc1FmT1prdHVRLzY0MD93eF9mbXQ9cG5nJnRwPXdlYnAmd3hmcm9tPTUmd3hfbGF6eT0xJnd4X2NvPTE)

如上图，当写请求发生时：

（1）写主库

（2）将哪个库，哪个表，哪个主键三个信息拼装一个key设置到cache里，这条记录的超时时间，设置为“主从同步时延”

*画外音：key的格式为“db:table:PK”，假设主从延时为1s，这个key的cache超时时间也为1s。*

 

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9ZcmV6eGNraFlPejAxY09TRDE0NnhuN1pFU0RIeFlsOHVXaWJaTzhGRkthaWNVSFo0aWF2RGliNk8wUlE3dmtjaFU3eDk1ZEw0YUtOZVVpY0M5N1FJY1R6bnNRLzY0MD93eF9mbXQ9cG5nJnRwPXdlYnAmd3hmcm9tPTUmd3hfbGF6eT0xJnd4X2NvPTE)

如上图，当读请求发生时：

这是要读哪个库，哪个表，哪个主键的数据呢，也将这三个信息拼装一个key，到cache里去查询，如果，

（1）**cache里有这个key**，说明1s内刚发生过写请求，数据库主从同步可能还没有完成，此时就应该去主库查询

（2）**cache里没有这个key**，说明最近没有发生过写请求，此时就可以去从库查询

以此，保证读到的一定不是不一致的脏数据。

[参考](https://blog.csdn.net/john1337/article/details/98850192)



## Redis穿透，雪崩。出现的情况和解决的办法 

### (一)  缓存雪崩

**缓存雪崩**是指缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

**解决方案**

1. 缓存数据的**过期时间设置随机**，防止同一时间大量数据过期现象发生。
2. 一般并发量不是特别多的时候，使用最多的解决方案是**加锁排队**。
3. 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则**更新数据缓存**。

### (二) 缓存穿透

**缓存穿透**是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

**解决方案**

1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的**直接拦截**；
2. 从缓存取不到的数据，在数据库中也没有取到，这时也可以将**key-value对写为key-null**，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
3. 采用**布隆过滤器**，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力

**附加**

对于空间的利用到达了一种极致，那就是Bitmap和布隆过滤器(Bloom Filter)。

* Bitmap： 典型的就是哈希表
  缺点是，Bitmap对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。

* 布隆过滤器（推荐）
  * 就是引入了k(k>1)个相互独立的哈希函数，保证在给定的空间、误判率下，完成元素判重的过程。
  * **优点：**是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。
  * **Bloom-Filter算法的核心思想：**就是利用多个不同的Hash函数来解决“冲突”。
    Hash存在一个冲突（碰撞）的问题，用同一个Hash得到的两个URL的值有可能相同。**为了减少冲突，我们可以多引入几个Hash，如果通过其中的一个Hash值我们得出某元素不在集合中，那么该元素肯定不在集合中。只有在所有的Hash函数告诉我们该元素在集合中时，才能确定该元素存在于集合中。这便是Bloom-Filter的基本思想。**
  * Bloom-Filter一般用于在大数据量的集合中判定某元素是否存在。

### (三)  缓存击穿

**缓存击穿**是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。**和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。**

**解决方案**

1. 设置**热点数据**永远不过期。
2. 加互斥锁，互斥锁

### (四)  缓存预热

**缓存预热**就是系统上线后，**将相关的缓存数据直接加载到缓存系统**。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

**解决方案**

1. 直接写个缓存刷新页面，上线时手工操作一下；
2. 数据量不大，可以在项目启动的时候自动进行加载；
3. 定时刷新缓存；

###  (五）缓存降级

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

**缓存降级**的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

1. 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
2. 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
3. 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
4. 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，**可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。**

###  (六) 热点数据和冷数据

* 热点数据，缓存才有价值，**访问多**

* 对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。**频繁修改的数据，看情况考虑使用缓存。**

**数据更新前至少读取两次，缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。**

那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时**就需要将数据同步保存到Redis缓存，减少数据库压力。**

### (六) 缓存热点key

缓存中的一个Key(比如一个促销商品)，**在某个时间点过期的时候**，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

**解决方案**

**对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁**；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询

[参考](https://blog.csdn.net/ThinkWon/article/details/103402008)

##  Redis的持久化机制有哪些？Redis如何进行快照？快照快结束时，发生写操作，写操作的数据是否会保存到快照？（我回答不会，快照的数据都是开始快照那个时刻的全量数据） 

持久化的目的主要是做灾难恢复，数据恢复。由于Redis的数据全都放在内存里面，如果Redis挂了，没有配置持久化的话，重启的时候数据会全部丢失。

**Redis持久化分为两种：**

- **RDB持久化**： 在指定的时间间隔内，将内存中的数据集**快照**写入磁盘，**实际操作过程是fork一个子进程**，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储 。

  *Redis 将某一时刻的快照保存成一种称为 RDB 格式的文件中。RDB 文件是一个经过压缩的二进制文件。通过该文件，Redis 可以将内存中的数据恢复成某一时刻的状态。*

  <img src="./img/RDB.jpg" alt="这里写图片描述" style="zoom:50%;" />

  

- **AOF持久化**： AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。





[参考](https://www.cnblogs.com/yzh-blog/p/11670762.html)